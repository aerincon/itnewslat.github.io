---
layout: posts
color-schema: red-dark
date: '2021-03-08 09:49 -0400'
published: true
superNews: false
superArticle: false
year: '2021'
title: Cuando los deepfakes se convierten en armas
image: >-
  https://raw.githubusercontent.com/itnewslat/assets/master/img/540x320/Noticias-p.jpg
detail-image: >-
  https://raw.githubusercontent.com/itnewslat/assets/master/img/1024x680/Noticias-g.jpg
categories:
  - Venezuela
  - Colombia
  - Argentina
  - Perú
  - Ecuador
  - Chile
  - Panama
tags:
  - Seguridad
week: '10'
---
<p style="text-align: justify;">Por <strong><em>Mauro Vicente, Regional Sales Manager Latam - Avast Business</em></strong></p>
<p style="text-align: justify;"><strong>Los seres humanos están fuertemente influenciados por su percepción visual. Reconocemos rápidamente lo que vemos con nuestros propios ojos como verdad. Pero, ¿qué sucede cuando ya no podemos confiar en nuestros sentidos? En los últimos años, el número de los llamados deepfakes ha aumentado constantemente, al igual que su calidad.
</strong></p>
<p style="text-align: justify;"><strong>¿Qué son los deepfakes?</strong></p>
<p style="text-align: justify;">Lo que comenzó como un software de edición de fotografías simple e inocente se ha convertido en una industria que busca sesgar el ecosistema en línea de información de video. Mediante el uso de programas profesionales para la edición de imágenes, sonido y video, así como el uso de herramientas compatibles con IA, ha habido grandes avances en el desarrollo de grabaciones de audio, imágenes y video falsificadas (deepfakes) en los últimos años.</p>
<p style="text-align: justify;">El experto en análisis de imágenes digitales, el profesor <a href="http://farid.berkeley.edu/">Hany Farid de UC Berkeley</a>, distingue los deepfakes en cuatro tipos generales:</p>

<ul style="text-align: justify;">
	<li><strong>La pornografía involuntaria</strong> es el ejemplo más común. El rostro de cualquier mujer u hombre se inserta en un video porno y se distribuye en línea.</li>
	<li><strong>Las campañas de desinformación</strong> tienen como objetivo difundir información falsa y engañar deliberadamente al público. A menudo abordan temas controvertidos con el objetivo de alimentar las discusiones que ya han surgido.</li>
	<li><strong>La falsificación de evidencia legal tiene</strong> como objetivo documentar eventos como la mala conducta policial que en realidad nunca ocurrieron.</li>
	<li><strong>El fraude clásico que utiliza nuevos medios </strong>también puede tener consecuencias penales o de seguridad. Un ejemplo de esto es un deepfake de audio de 2019 que solicita <a href="https://www.trendmicro.com/vinfo/us/security/news/cyber-attacks/unusual-ceo-fraud-via-deepfake-audio-steals-us-243-000-from-u-k-company">una transferencia de una empresa de energía del Reino Unido</a>. El audio encarnaba al director ejecutivo de la empresa.</li>
</ul>
<p style="text-align: justify;"><strong>Identificar y reconocer deepfakes</strong></p>
<p style="text-align: justify;">Pero, ¿cómo reconoces estas falsificaciones? Una posibilidad es analizar las peculiaridades y expresiones faciales con mucho cuidado e identificar las peculiaridades de cada persona. Farid llama a esto "biometría suave" porque no es una ciencia exacta, como el ADN o las huellas dactilares, que pueden identificar a alguien de manera muy confiable. La previsibilidad aumenta con las celebridades filmadas con frecuencia, de las cuales existe una gran cantidad de material de video existente que se puede usar para comparar con los "ticks" visuales. Por ejemplo, si intenta decir las palabras “madre”, “hermano” y “padres” sin cerrar la boca, rápidamente descubrirá que solo los ventrílocuos pueden hacerlo. Cuando Alec Baldwin hace sus imitaciones de Trump, no entiende estas peculiaridades faciales, lo que sugiere una falsificación.</p>
<p style="text-align: justify;"><strong>Las plataformas de redes sociales deben ser proactivas</strong></p>
<p style="text-align: justify;">Tenemos algunos desafíos. Primero, la tecnología está evolucionando rápidamente y mejorando cada vez más en la creación de deepfakes convincentes. La velocidad de transmisión en las redes sociales también está aumentando. Lo que solía tomar días o semanas ahora se logra en horas o incluso minutos. El público está polarizado ahora. Esto significa que la gente está dispuesta a creer lo peor de aquellos que no están de acuerdo o que no les agradan en particular. También hay un aumento en lo que el profesor Farid llama el "dividendo mentiroso". Esto significa que la mera afirmación de que algo es falso suele ser suficiente para neutralizarlo, incluso si no es cierto. Las personas que ya han sido criticadas por una determinada mala conducta pueden afirmar cada vez más fácilmente que los archivos incriminatorios son falsificados. Como resultado, también se cuestiona la credibilidad de las instancias auténticas.</p>
<p style="text-align: justify;">No hay una solución fácil para acabar con el apocalipsis de la desinformación. En cambio, las plataformas sociales deben asumir la responsabilidad y poner un mejor etiquetado con un enfoque más fuerte en regular el alcance y presentar puntos de vista alternativos, en lugar de simplemente eliminar contenido ofensivo o falso.</p>

![](https://raw.githubusercontent.com/itnewslat/assets/master/img/540x320/Noticias-p.jpg)

<img src="https://tracker.metricool.com/c3po.jpg?hash=56f88a41e39ab42c063cc51676587a04"/>