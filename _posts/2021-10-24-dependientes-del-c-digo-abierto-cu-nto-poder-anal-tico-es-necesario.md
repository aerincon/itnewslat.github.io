---
layout: posts
color-schema: red-dark
date: '2021-10-24 18:50 -0500'
published: true
superNews: false
superArticle: false
year: '2021'
title: 'Dependientes del código abierto: ¿cuánto poder analítico es necesario?'
detail-image: >-
  https://raw.githubusercontent.com/itnewslat/assets/master/img/1024x680/fico-alianza-g.jpg
image: >-
  https://raw.githubusercontent.com/itnewslat/assets/master/img/540x320/fico-alianza-p.jpg
categories:
  - Venezuela
  - Colombia
  - Argentina
  - Perú
  - Ecuador
  - Chile
  - Panama
  - Mexico
tags:
  - Actualidad
week: '42'
---
- Los científicos de datos necesitan justificar la necesidad del riesgo incremental que asumimos cuando utilizamos métodos más complicados para resolver un problema —y dejar de ser dependientes del código abierto


En los años que llevo recorriendo pendientes imposibles y caminos rocosos, he aprendido que manejar un todo terreno es muy parecido a resolver problemas analíticos: es contraproducente utilizar más caballos de fuerza de los que necesitas.  

¿Cuánto poder predictivo es suficiente?
Existe una amplia variedad de herramientas analíticas de código abierto gratuitas para los científicos de datos y los estudiantes, quienes participan en las competencias de Kaggle. Esta famosa plataforma de competencias de desarrollo de modelos predictivos y análisis es propiedad de Google, y su prevalencia en la ideología de la comunidad analítica es en sí misma una cuestión inquietante. El problema específico con Kaggle es que exhorta implícitamente a utilizar el mayor poder analítico posible para resolver sus acertijos, sin importar que ese método sea apropiado o no aplicable en el mundo real.

Un ejemplo de cómo ese tipo de análisis excesivo genera resultados contaminados es la idea del volcado de datos: verter tantas fuentes de datos como sea posible a través de un modelo para obtener una mejora diminuta en su poder predictivo, sin entender qué relaciones nuevas (y probablemente insignificantes) se están aprendiendo, además de no considerar la confluencia de la complejidad del modelo.   

El exceso de análisis es un ganador en Kaggle, pero no así en el mundo real. He aquí mis opiniones, al respecto:

Considero que eso es poco ortodoxo en el mundo de la ciencia de datos: lo explicable primero, el poder predictivo después, una noción que es más importante que nunca para las compañías que se encuentran implementando inteligencia artificial (IA).

Una IA que sea explicable permite a los humanos encontrar respuestas a preguntas importantes, tales como:

- ¿El modelo se desarrolló de manera adecuada?
- ¿Cuáles son los riesgos de utilizar el modelo?
- ¿Cuándo se degradará el modelo?
- Rehabilitación para los dependientes del código abierto  
- “Adictos al código abierto” es el término que utilizo para referirme a los científicos de datos que emplean poder analítico excesivo para resolver un problema. La buena noticia es que hay un camino directo a la rehabilitación. Tal como lo expresó el genio de la industria de IA, Andrew Ng, la idea es: “Empezar siempre con la tecnología más sencilla y luego justificar por qué debes usar métodos más complejos”. Por lo tanto, las preguntas que debemos plantearnos respecto al diseño de modelos son:
- ¿Cómo de bien entendemos el problema que estamos resolviendo? ¿Deberíamos conversar con la empresa para obtener una perspectiva clara para diseñar el modelo?
- ¿Cuáles son las fuentes de datos adecuadas que se deben incluir? ¿Qué variables/características clave derivaremos de estas fuentes?
- ¿Qué tan eficaz es nuestro modelo más sencillo; por ejemplo, una regresión? ¿Cumple con los requisitos de la empresa? ¿Cuáles son los impulsores de este modelo?
- A medida que agregamos complejidad al modelo, ¿qué ganamos en predicción y qué perdemos en capacidad explicativa? ¿Robustez? ¿Ética?
- ¿Debemos dar el salto a modelos de aprendizaje automático interpretables?


Básicamente, necesitamos justificar la necesidad del riesgo incremental que asumimos cuando utilizamos métodos más complicados. Como científicos de datos, debemos preguntarnos: ¿Qué pretendemos lograr? ¿Cuáles son las tecnologías adecuadas para lograrlo? ¿Qué debemos sacrificar? Los sacrificios inaceptables incluyen violaciones a las legislaciones de protección de datos y una IA que no sea ética.

La educación es fundamental
Retomando mi analogía de una todo terreno, si veo una cuesta llena de rocas e intento subirla, sé que podré lograrlo, ¿pero qué sendero elegiré? Subiré de forma lenta y estable por la cuesta y sobre las rocas, sin gran esfuerzo, sin forzar el motor. Aquellos que lleven los caballos de fuerza de su auto al límite sobre un terreno difícil serán los que volcarán y romperán sus vehículos. En estas condiciones, lento es rápido (¡e inteligente!). Cuando se trata de desarrollar tecnologías adecuadas de inteligencia artificial y aprendizaje automático, lento también es rápido.  

Eso nos lleva a considerar la importancia de la capacitación. Los científicos de datos necesitan tener una perspectiva más amplia no sólo sobre  la ciencia de los datos, sino también del contexto empresarial y social en el que se utilizará su trabajo.

**Scott Zoldi**
Chief Analytics Officer de FICO

![](https://raw.githubusercontent.com/itnewslat/assets/master/img/540x320/fico-alianza-p.jpg)

<table style="height: 42px;" width="569">
<tbody>
<tr>
<td style="text-align: justify;"><sub><strong>Nuestras noticias también son publicadas a través de nuestra cuenta en Twitter <a href="https://twitter.com/itnewslat?lang=es">@ITNEWSLAT</a> y en la aplicación <a href="https://squidapp.co/en/">SQUID</a></strong></sub></td>
</tr>
</tbody>
</table>

<img src="https://tracker.metricool.com/c3po.jpg?hash=56f88a41e39ab42c063cc51676587a04"/>
